#+Title: Expressive Parallel Analytics in Clojure
#+Author:
#+Email:

#+REVEAL_EXTRA_CSS: ./reveal.js/lib/css/zenburn.css
#+REVEAL_MATHJAX_URL: MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML
#+REVEAL_THEME: solarized
#+OPTIONS: num:nil toc:nil reveal_mathjax:t reveal_history:t reveal_control:nil reveal_progress:nil
#+REVEAL_TRANS: fade

* Who am I?

#+BEGIN_NOTES
- Was CTO of medium-sized data analytics company
- Switched to Clojure 4 years ago
- Left to write a book 1 year ago
- Now a freelance data scientist and data engineer
#+END_NOTES

* Mission-critical data

[[./images/mastodon.png]]

[[./images/the-wur.png]]

#+BEGIN_NOTES
- Released a few weeks ago
- New methodology
- New implementation
- Clojure!
#+END_NOTES

* Stats

https://www.timeshighereducation.com/news/ranking-methodology-2016

- 13 performance indicators
- 10 quotient indicators
- 4  weighted quotients across 6 subjects
- 800+ institutions
- 7  ranking tables

#+BEGIN_NOTES
- Won't speak in detail about methodology
- Gives a flavour for the kinds of problems I'm addressing.
#+END_NOTES

* Analytic pipeline

- load rows
- calculate summary statistics
- process rows w.r.t. summary statistics
- [further processing]
- output
- x 13 x 7

#+BEGIN_NOTES
- Normalise, calculate CDFs

- This is data engineering
- Want to productionise sexy algorithm
- Maybe you're building an intricate data processing system

- Set context...
#+END_NOTES

* Nope

#+BEGIN_SRC javascript
do_something()
do_something_else()
then_do_this()
#+END_SRC

#+BEGIN_NOTES
- Not talking about global state
- What languages are people using? (Python, R, SAS, Scala, Clojure?)
#+END_NOTES

* Pipe.line()

#+BEGIN_SRC javascript
PipeLine.doSomething().doSomethingElse().thenDoThis()
#+END_SRC

#+BEGIN_NOTES
- Familiar if you've used Spark (RDDs)
#+END_NOTES

* (Pipeline :-)

#+BEGIN_SRC clojure
(then-do-this (do-something-else (do-something)))
#+END_SRC

#+BEGIN_NOTES
- We're in Clojure-land
- Parens in a different place

- Let's use a concrete example...
#+END_NOTES

* Threading

#+BEGIN_SRC clojure
(->> (load-data "data.edn")
     (select-relevant)
     (convert-currency)
     (assign-score))
#+END_SRC

#+BEGIN_NOTES
- Add sample data

- Thread-last Macro

- What are those functions doing?
#+END_NOTES

* Enter Sequence-processing functions

- map
- filter
- remove
- keep
- take
- partition

#+BEGIN_NOTES
- No reduce. Reduce takes a whole sequence and returns one thing
- Take and partition are stateful
#+END_NOTES

* Threading II

#+BEGIN_SRC clojure
(->> (load-data "data.edn")
     (filter relevant?)
     (map convert-currency)
     (map assign-score))

;;({:name "A", :fx 0.8, :a 112.5, :b 62.5, :score 175.0}
;; {:name "B", :fx 0.2, :a 400.0, :b 400.0, :score 800.0}
;; {:name "D", :fx 0.5, :a 100.0, :b 140.0, :score 240.0})
#+END_SRC

#+BEGIN_NOTES
- Standard sequence functions
- Familiar to anyone who has done Spark

- Problem 1:
- Processing is bound to data
#+END_NOTES

* Solved?

#+BEGIN_SRC clojure
(defn process [data]
  (->> (filter relevant? data)
       (map convert-currency)
       (map assign-score)))

(process (load-data "data.edn"))

;;({:name "A", :fx 0.8, :a 112.5, :b 62.5, :score 175.0}
;; {:name "B", :fx 0.2, :a 400.0, :b 400.0, :score 800.0}
;; {:name "D", :fx 0.5, :a 100.0, :b 140.0, :score 240.0})
#+END_SRC

#+BEGIN_NOTES
- We can paramaterise 'data'

- But the map and filter still make assumptions about the container
#+END_NOTES

* ...Not really

#+BEGIN_SRC clojure
(def v [1 2 3 4])
;; #'user/v

(type v)
;; clojure.lang.PersistentVector

(type (map inc v))
;; clojure.lang.LazySeq

(type (mapv inc v))
;; clojure.lang.PersistentVector
#+END_SRC

#+BEGIN_NOTES
- Map and mapv are tied to concrete representations

- Also intermediate collections, space and time hungry
#+END_NOTES

* Enter Transducers

[[./images/decorator.png]]

#+BEGIN_NOTES
- Introduced in Clojure 1.7 around a year ago
- Separate the transformation from the source AND sink
#+END_NOTES

* No Seq in Sight

#+BEGIN_SRC clojure
(def xform
  (comp (filter relevant?)
        (map convert-currency)
        (map assign-score)))
#+END_SRC

#+BEGIN_NOTES
- This is Clojure 1.7 map and filter
- They have become transducers
- Their composition is also a transducer

- See it in use
#+END_NOTES

* Add the sequence

#+BEGIN_SRC clojure
(sequence xform (load-data "data.edn"))

;;({:name "A", :fx 0.8, :a 112.5, :b 62.5, :score 175.0}
;; {:name "B", :fx 0.2, :a 400.0, :b 400.0, :score 800.0}
;; {:name "D", :fx 0.5, :a 100.0, :b 140.0, :score 240.0})
#+END_SRC

#+BEGIN_NOTES
- 1.7 introduces sequence function
- Produces lazy sequence
#+END_NOTES

* It is an open system

#+BEGIN_SRC clojure
(->> (load-data "data.edn")
     (sequence (comp xform (take 2))))

;;({:name "A", :fx 0.8, :a 112.5, :b 62.5, :score 175.0}
;; {:name "B", :fx 0.2, :a 400.0, :b 400.0, :score 800.0})

(->> (load-data "data.edn")
     (sequence (comp xform (map :score))))

;; (175.0 800.0 240.0)
#+END_SRC

#+BEGIN_NOTES
- Compose transducers to get another transducer

- Take score as example, how would we sum up?
#+END_NOTES

* Sum up a sequence

#+BEGIN_SRC clojure
(->> (load-data "data.edn")
     (sequence (comp xform (map :score)))
     (reduce +))

;; 1215.0
#+END_SRC

#+BEGIN_NOTES
- Added intermediate collection back
#+END_NOTES

* Transduce

#+BEGIN_SRC clojure
(->> (load-data "data.edn")
     (transduce (comp xform (map :score)) +))

;; 1215.0
#+END_SRC

#+BEGIN_NOTES
- Transduce added in Clojure 1.7
- Takes a transformation and a step function

- What does a step function look like?
#+END_NOTES

* Reducing step function

#+BEGIN_SRC clojure
(+)
;; 0

(+ 42)
;; 42

(+ 21 21)
;; 42
#+END_SRC

#+BEGIN_SRC clojure
(conj)
;; []

(conj [42])
;; [42]

(conj [21] 21)
;; [21 21]
#+END_SRC

* An IQR step function

https://github.com/HdrHistogram/HdrHistogram

#+BEGIN_SRC clojure
(defn hist-iqr
  ;; Zero arity init
  ([] (DoubleHistogram. 1e8 3))
  
  ;; Two arity step
  ([hist x]
   (doto hist
     (.recordValue x)))

  ;; Single arity complete
  ([hist]
   (vector (.getValueAtPercentile hist 25)
           (.getValueAtPercentile hist 75))))
#+END_SRC

#+BEGIN_NOTES
- Init is optional
#+END_NOTES

* Using the custom step

#+BEGIN_SRC clojure
(->> (load-data "data.edn")
     (transduce (comp xform (map :score)) hist-iqr))

;; [175.0 240.0]
#+END_SRC

#+BEGIN_NOTES
- Identical transformer, very different output
#+END_NOTES

* Sequential processing

#+BEGIN_SRC clojure
(defn iqr-sequence [xform data]
  (let [[from to] (->> data
                       (transduce (comp xform (map :score)) hist-iqr))]
    (->> data
         (sequence (comp xform (filter #(<= from (:score %) to)))))))
#+END_SRC

#+BEGIN_NOTES
- Destructure IQR
- No additional sequences created

- Let's assume we want to calculate mean...
#+END_NOTES

* Mean step function

#+BEGIN_SRC clojure
(defn mean-step
  ([] {:sum 0 :count 0})
  ([accum x]
   (-> (update-in accum [:count] inc)
       (update-in [:sum] + x)))
  ([{:keys [sum count]}]
   (/ sum count)))

(->> (load-data "data.edn")
     (transduce (comp xform (map :score)) mean-step))

;; 405.0
#+END_SRC

#+BEGIN_NOTES
- Once again:
- init
- step
- completion

NB: mean-step - will refer to later
#+END_NOTES

* Mean of the IQR

#+BEGIN_SRC clojure
(defn iqr-mean [xform data]
  (let [[from to] (->> data
                       (transduce (comp xform (map :score)) hist-iqr))]
    (->> data
         (transduce (comp xform
                     (filter #(<= from (:score %) to))
                     (map :score))
                    mean-step))))

;; 207.5
#+END_SRC

#+BEGIN_NOTES
- No intermediate collections

- Are we done? No - parallelism
#+END_NOTES


* Diagram

We want to avoid making serial folds over the data.

..Diagram..

* Juxt

(map (juxt mean-step sd-step))

#+BEGIN_NOTES
- This doesn't work because the same arguments are passed to each step function

- Each step function maintains its own accumulator
#+END_NOTES


* Fuse steps
#+BEGIN_SRC clojure
(defn fuse [named-steps]
  (fn
    ([]
     (reduce (fn [m [k v]]
               (assoc m k (v))) {} named-steps))
    ([accum x]
     (reduce (fn [m [k v]]
               (update-in m [k] v x)) accum named-steps))
    ([accum]
     (reduce (fn [m [k v]]
               (update-in m [k] v)) accum named-steps))))
#+END_SRC

* Transducer composition

We're used to transforming a sequence with a function.

What about transforming a function with a sequence?

#+BEGIN_SRC clojure
(defn pipeline
  "Uses xs to adjust xform by appending normalization step"
  [xform xs]
  (let [aggregates (transduce xform
                              (fuse {:mean mean-step
                                     :sd   sd-step})
                              xs)]
    (comp xform (map "normalize magic goes here"))))
#+END_SRC

* Enter Reducers

- Pre-date transducers
- Also aim to reduce number of intermediate collections
- Bring parallelism through Java's fork/join

#+BEGIN_NOTES
- Fork / join available in Java 7 +
- Available since 2011
#+END_NOTES

* Fork / Join

#+BEGIN_SRC txt
solve(problem):
    if problem is small enough:
        solve problem directly (sequential algorithm)
    else:
        for part in subdivide(problem)
            fork subtask to solve part
        join all subtasks spawned in previous loop
        combine results from subtasks
#+END_SRC

#+BEGIN_NOTES
- We can already solve the subparts
- We need a way to combine their results

- Not combine like Hadoop combiner
#+END_NOTES

* Parallel reduce / combine

[[./images/reductions-tree.png]]

* ...schematically

[[./images/reduce-combine.png]]

* Mean reducers

#+BEGIN_SRC clojure
(require ['clojure.core.reducers :as r])

(defn mean-step
  ([] {:sum 0 :count 0})
  ([accum x]
   (-> (update-in accum [:count] inc)
       (update-in [:sum] + x)))
  ([{:keys [sum count]}]
   (/ sum count)))

(defn mean-combiner
  ;; Combiner is used for init value
  ([] {:sum 0 :count 0})
  ([a b]
   (merge-with + a b)))

(->> (load-data "data.edn")
     (into [] (comp xform (map :score)))
     (r/fold mean-combiner mean-step))

;; {:sum 1215.0, :count 3}
#+END_SRC

#+BEGIN_NOTES
- Fold takes the combiner and step function

- Using into Clojure's generic collection
- Again, intermediate collection before fold
- The completion function isn't called
#+END_NOTES

* Intermediate collections revisited

#+BEGIN_SRC clojure
(def scorer
  (comp xform (map :score)))

(->> (load-data "data.edn")
     (into [] scorer)
     (r/fold mean-combiner mean-step))

;; {:sum 1215.0, :count 3}

(->> (load-data "data.edn")
     (r/fold mean-combiner (scorer mean-step)))

;; {:sum 1215.0, :count 3}
#+END_SRC

#+BEGIN_NOTES
- Scorer is our transducer
- Getting a reducing function 'out of' a transducer
#+END_NOTES

* Get a reducing function back out

#+BEGIN_SRC clojure
(let [f (weighted-avg :a :b)]
 (reduce f (f) [{:a 1 :b 2} {:a 4 :b 8}]))

;; [[#object[example.core$wrapping$fn__80296 0x3f478522 "example.core$wrapping$fn__80296@3f478522"] #object[clojure.lang.Volatile 0x573499fb {:status :ready, :val {:sum 5, :count 2}}]] [#object[example.core$wrapping$fn__80296 0x414f525c "example.core$wrapping$fn__80296@414f525c"] #object[clojure.lang.Volatile 0x179ba0e5 {:status :ready, :val {:sum 10, :count 2}}]]]
#+END_SRC

* Anatomy of a transducer

#+BEGIN_SRC clojure
(defn filter' [pred]
  (fn [rf]
    (fn
      ([] (rf))
      ([result] (rf result))
      ([result input]
       (if (pred input)
         (rf result input)
         result)))))

(transduce (filter' even?) conj [1 2 3 4 5 6])

;; [2 4 6]
#+END_SRC

#+BEGIN_NOTES
- transducers are just functions of 3 arities
- arity zero is init
- arity one is completion
- arity two is the reducing function
- all just function composition
- these ideas are general
#+END_NOTES

* Enter core.async

Core async has a reduce, but no combine.

Combine is just another reduce over the intermediate steps.

#+BEGIN_SRC clojure
(defn pipeline-r [n f g xs]
  (let [in (async/chan n)]
    (async/onto-chan in xs)
    (->> (for [_ (range n)]
           (async/reduce f (f) in))
         (async/merge)
         (async/reduce g (g))
         (async/<!!)
         (f))))
#+END_SRC

* Calculating variance
 
#+BEGIN_SRC clojure
{:reducer-identity (constantly [0 0 0])
 :reducer (fn count-mean-sq [[count mean sum-of-squares] x]
            (let [count' (inc count)
                  mean'  (+ mean (/ (- x mean) count'))]
              [count'
               mean'
               (+ sum-of-squares (* (- x mean') (- x mean)))]))
 :post-reducer identity
 :combiner-identity (constantly [0 0 0])
 :combiner (fn partcmsq [[c m sq] [c2 m2 sq2]]
             (let [count (+ c c2)]
               (if (zero? count)
                 [c m sq]
                 [count
                  (/ (+ (* c m) (* c2 m2)) count)
                  (+ sq sq2 (/ (* (- m2 m) (- m2 m) c c2) count))])))
 :post-combiner (fn vardiv [x]
                  (double (/ (last x) (core/max 1 (dec (first x))))))}
#+END_SRC

* Simple Regression

#+BEGIN_SRC clojure
(defn calculate-coefficients [{:keys [covariance variance-x
                                      mean-x mean-y]}]
  (let [slope (/ covariance variance-x)]
    {:intercept (- mean-y (* mean-x slope))
     :slope     slope}))

(defn linear-regression [fx fy fold]
  (->> fold
       (t/fuse {:covariance (m/covariance fx fy)
                :variance-x (m/variance (t/map fx))
                :mean-x (m/mean (t/map fx))
                :mean-y (m/mean (t/map fx))})
       (t/post-combine calculate-coefficients)))

(def linear-regression-fold
  (->> (t/filter relevant?)
       (t/map convert-currency)
       (linear-regression :a :b)))

(-> (t/chunk 1024 (load-data "data.edn"))
    (t/tesser linear-regression-fold))

;; {:intercept 68.05555555555557, :slope 0.6666666666666666}
#+END_SRC

#+BEGIN_NOTES
- Having calculated many statistics
- Want to perform some post-processing on the results
- Keep it within the fold

- Where's my cake?
#+END_NOTES


* Reducing function Rules
- Always call completion
- Respect reduced
* Summary

- Separate process from substrate
- Transducers, step functions and transducible processes
- Reducing and combining functions
- Create composable, extensible units of computation
- Defer decisions about context
- Benefit

* Thanks!

https://github.com/henrygarner/data-science-london-oct-2015

[[./images/henrygarner.jpeg]]

Henry Garner

@henrygarner

* If you liked this...

http://cljds.com/cljds-book | 
http://cljds.com/cljds-amzn

[[./images/clojure-data-science.png]]

#+BEGIN_NOTES
- This is new material
- Cover Clojure applied to statistical analysis
- Ideally you know a little Clojure already
- Learn statistics and machine learning with Clojure
#+END_NOTES
* References

https://github.com/cgrand/xforms
https://github.com/aphyr/tesser
