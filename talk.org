#+Title: Expressive Parallel Analytics with Transducers
#+Author:
#+Email:

#+REVEAL_THEME: zenburn
#+REVEAL_EXTRA_CSS: ./extra.css
#+OPTIONS: num:nil toc:nil reveal_mathjax:t reveal_history:t reveal_control:nil reveal_progress:nil reveal_center:nil
#+REVEAL_TRANS: none
# #+REVEAL_PLUGINS: (highlight)

* Who am I?

#+BEGIN_NOTES
- Was CTO of medium-sized data analytics company
- Switched to Clojure 4 years ago
- Left to write a book 1 year ago
- Now a freelance data scientist and data engineer
#+END_NOTES

* Mission-critical analysis

[[./images/mastodon.png]]

[[./images/the-wur.png]]

#+BEGIN_NOTES
- Not going to cover anything especially new
- Encourage you to look closer at some of what Clojure already provides
- Give you some new ways to solve existing problems

- Released a couple of months ago
- New methodology
- New implementation
- Clojure!
#+END_NOTES

* Metastatistics

https://www.timeshighereducation.com/news/ranking-methodology-2016

- 13 performance indicators
- 10 quotient indicators
- 4  weighted quotients across 6 subjects
- 1,000+ institutions
- 7 ranking tables

#+BEGIN_NOTES
- Won't speak in detail about methodology
- Gives a flavour for the kinds of problems I'm addressing.
#+END_NOTES

* Annoying-sized data

#+BEGIN_NOTES
- Not large enough for Hadoop
- Large enough to be worth optimizing


#+END_NOTES

* Analytic sequence

#+ATTR_REVEAL: :frag (appear appear appear appear appear) :frag_idx (1 1 1 4)
1. Load & join
2. Apply rules
   #+ATTR_REVEAL: :frag (appear appear appear) :frag_idx (2 2 2)
   1. Apply filters
   2. Normalise data
      #+ATTR_REVEAL: :frag (appear appear appear) :frag_idx (3 3 3)
      1. Harmonise units
      2. Summary statistics
      3. Harmonise ranges
   3. Calculate score
3. Output
4. x 13 x 7

#+BEGIN_NOTES
- Normalise, calculate CDFs

- This is data engineering
- Want to productionise sexy algorithm
- Maybe you're building an intricate data processing system
#+END_NOTES

* Thread-last

#+BEGIN_SRC clojure
(->> (load-data "data.edn")
     (select-relevant)  ;; Apply filters
     (convert-currency) ;; Normalize 
     (assign-score))
#+END_SRC

#+BEGIN_NOTES
- Add sample data

- Thread-last Macro

- What are those functions doing?
#+END_NOTES

* Sequence functions

- map
- filter
- remove
- keep
- take
- partition

#+BEGIN_NOTES
- No reduce. Reduce takes a whole sequence and returns one thing
- Take and partition are stateful
#+END_NOTES

* Threading II

#+BEGIN_SRC clojure
(->> (load-data "data.edn")
     (filter relevant?)
     (map convert-currency)
     (map assign-score))

;;({:name "A", :fx 0.8, :a 112.5, :b 62.5, :score 175.0}
;; {:name "B", :fx 0.2, :a 400.0, :b 400.0, :score 800.0}
;; {:name "D", :fx 0.5, :a 100.0, :b 140.0, :score 240.0})
#+END_SRC

#+BEGIN_NOTES
- Standard sequence functions
- Familiar to anyone who has done Spark

- Problem 1:
- Processing is bound to data
#+END_NOTES

* Mapping

(Image of guitar and amp)

#+BEGIN_NOTES
- We have a sequence being transformed

- Sound waves being amplified
#+END_NOTES

* Solved?

#+BEGIN_SRC clojure
(defn process [data]
  (->> (filter relevant? data)
       (map convert-currency)
       (map assign-score)))

(process (load-data "data.edn"))

;;({:name "A", :fx 0.8, :a 112.5, :b 62.5, :score 175.0}
;; {:name "B", :fx 0.2, :a 400.0, :b 400.0, :score 800.0}
;; {:name "D", :fx 0.5, :a 100.0, :b 140.0, :score 240.0})
#+END_SRC

#+BEGIN_NOTES
- We can paramaterise 'data'

- But the map and filter still make assumptions about the container
#+END_NOTES

* ...Not really

#+BEGIN_SRC clojure
(def v [1 2 3 4])
;; #'user/v

(type v)
;; clojure.lang.PersistentVector

(type (map inc v))
;; clojure.lang.LazySeq

(type (mapv inc v))
;; clojure.lang.PersistentVector
#+END_SRC

#+BEGIN_NOTES
- Map and mapv are tied to concrete representations

- Also intermediate collections, space and time hungry
#+END_NOTES

* Enter Transducers

[[./images/decorator.png]]

#+BEGIN_NOTES
- Introduced in Clojure 1.7 around a year ago
- Separate the transformation from the source AND sink
#+END_NOTES

* Effects pedals and speaker

(Image of effects pedals board)

#+BEGIN_NOTES
- The effects pedals (the transform)

- Separate from the sink
#+END_NOTES

* No Seq in Sight

#+BEGIN_SRC clojure
(def xform
  (comp (filter relevant?)
        (map convert-currency)
        (map assign-score)))
#+END_SRC

#+BEGIN_NOTES
- This is our effects board
- This is Clojure 1.7 map and filter
- They have become transducers
- Their composition is also a transducer

- See it in use
#+END_NOTES

* Add the sequence

#+BEGIN_SRC clojure
(sequence xform (load-data "data.edn"))

;;({:name "A", :fx 0.8, :a 112.5, :b 62.5, :score 175.0}
;; {:name "B", :fx 0.2, :a 400.0, :b 400.0, :score 800.0}
;; {:name "D", :fx 0.5, :a 100.0, :b 140.0, :score 240.0})
#+END_SRC

#+BEGIN_NOTES
- 1.7 introduces sequence function
- Produces lazy sequence
#+END_NOTES

* It's an open system

#+BEGIN_SRC clojure
(->> (load-data "data.edn")
     (sequence (comp xform (take 2))))

;;({:name "A", :fx 0.8, :a 112.5, :b 62.5, :score 175.0}
;; {:name "B", :fx 0.2, :a 400.0, :b 400.0, :score 800.0})

(->> (load-data "data.edn")
     (sequence (comp xform (map :score))))

;; (175.0 800.0 240.0)
#+END_SRC

#+BEGIN_NOTES
- Compose transducers to get another transducer

- Take score as example, how would we sum up?
#+END_NOTES

* Sum up a sequence

#+BEGIN_SRC clojure
(->> (load-data "data.edn")
     (sequence (comp xform (map :score)))
     (reduce +))

;; 1215.0
#+END_SRC

#+BEGIN_NOTES
- Added intermediate collection back
#+END_NOTES

* Image of mic'd amp

#+BEGIN_NOTES
- Why the intermediate step?

- We can process directly into sink
#+END_NOTES

* Transduce

#+BEGIN_SRC clojure
(->> (load-data "data.edn")
     (transduce (comp xform (map :score)) +))

;; 1215.0
#+END_SRC

#+BEGIN_NOTES
- Transduce added in Clojure 1.7
- Takes a transformation and a step function

- What does a step function look like?
#+END_NOTES

* Reducing functions

#+BEGIN_SRC clojure
(+)
;; 0

(+ 42)
;; 42

(+ 21 21)
;; 42
#+END_SRC

#+BEGIN_SRC clojure
(conj)
;; []

(conj [42])
;; [42]

(conj [21] 21)
;; [21 21]
#+END_SRC

#+BEGIN_NOTES
- Init it optional
#+END_NOTES

* Interquartile range

https://github.com/HdrHistogram/HdrHistogram

#+BEGIN_SRC clojure
(defn hist-iqr
  ;; Zero arity init
  ([] (DoubleHistogram. 1e8 3))
  
  ;; Two arity step
  ([hist x]
   (doto hist
     (.recordValue x)))

  ;; Single arity complete
  ([hist]
   (vector (.getValueAtPercentile hist 25)
           (.getValueAtPercentile hist 75))))
#+END_SRC

#+BEGIN_NOTES
- Init is optional
#+END_NOTES

* Using the custom step

#+BEGIN_SRC clojure
(->> (load-data "data.edn")
     (transduce (comp xform (map :score)) hist-iqr))

;; [175.0 240.0]
#+END_SRC

#+BEGIN_NOTES
- Identical transformer, very different output
#+END_NOTES

* Steps

#+BEGIN_SRC clojure
(defn in-range [f from to]
  (filter #(<= from (f %) to))

(defn iqr-sequence [xform data]
  (let [[from to] (->> data
                       (transduce (comp xform (map :score)) hist-iqr))]
    (->> data
         (sequence (comp xform (in-range :score from to)))))
#+END_SRC

#+BEGIN_NOTES
- Destructure IQR
- No additional sequences created

- Let's assume we want to calculate mean...
#+END_NOTES

* Mean reducing function

TODO: better name (maybe just mean?)

#+BEGIN_SRC clojure
(defn mean-step
  ([] {:sum 0 :count 0})
  ([accum x]
   (-> (update-in accum [:count] inc)
       (update-in [:sum] + x)))
  ([{:keys [sum count]}]
   (/ sum count)))

(->> (load-data "data.edn")
     (transduce (comp xform (map :score)) mean-step))

;; 405.0
#+END_SRC

#+BEGIN_NOTES
- Once again:
- init
- step
- completion

NB: mean-step - will refer to later
#+END_NOTES

* Mean of the IQR

#+BEGIN_SRC clojure
(defn iqr-mean [xform data]
  (let [[from to] (->> data
                       (transduce (comp xform (map :score)) hist-iqr))]
    (->> data
         (transduce (comp xform
                     (in-range :score from to)
                     (map :score))
                    mean-step))))

;; 207.5
#+END_SRC

#+BEGIN_NOTES
- No intermediate collections

- Are we done? No - parallelism
#+END_NOTES

* Concurrent calculation

What if we want to calculate the mean and the standard deviation?

* Juxt

#+BEGIN_SRC clojure
  (juxt :a :b)
#+END_SRC

* Juxt

#+BEGIN_SRC clojure
(juxt mean-step sd-step)
#+END_SRC

#+BEGIN_NOTES
- This doesn't work because the same arguments are passed to each step function

- Each step function maintains its own accumulator
#+END_NOTES

* Juxt

#+BEGIN_SRC clojure
(defn simple-juxt [& rfns]
  (fn
    ([]      (mapv (fn [f]   (f))     rfns))
    ([acc]   (mapv (fn [f a] (f a))   rfns acc))
    ([acc x] (mapv (fn [f a] (f a x)) rfns acc))))

(def rf
  (simple-juxt + conj))

(transduce (map identity) rf (range 10))

;; => [45 [0 1 2 3 4 5 6 7 8 9]]
#+END_SRC

#+BEGIN_NOTES
Simple juxt acts as a proxy for each reducing function
#+END_NOTES

* Early termination

#+BEGIN_SRC clojure
(def rf
  (simple-juxt + ((take 3) conj)))

(transduce (map identity) rf (range 10))

;; => [45 #object[clojure.lang.Reduced 0x643ea00c {:status :ready, :val [0 1 2]}]]
#+END_SRC

#+BEGIN_NOTES
Reducing functions must honour "reduced?"
#+END_NOTES

* Juxt

#+BEGIN_SRC clojure
(defn juxt [& rfns]
  (fn
    ([]    (mapv (fn [f] (f)) rfns))
    ([acc] (mapv (fn [f a] (f (unreduced a))) rfns acc))
    ([acc x]
     (let [all-reduced? (volatile! true)
           results (mapv (fn [f a]
                           (if (reduced? a) a
                               (do (vreset! all-reduced? false)
                                   (f a x))))
                         rfns acc)]
       (if @all-reduced? (reduced results) results)))))

(def rf
  (juxt + ((take 3) conj)))

(transduce (map identity) rf (range 10))

;; => [45 [0 1 2]]
#+END_SRC

* Facet

#+BEGIN_SRC clojure
(defn facet [rf fns]
  (->> (map (fn [f] ((map f) rf)) fns)
       (apply juxt)))

(def rf
  (facet conj [inc dec]))

(transduce (map identity) rf (range 10))

;; => [[1 2 3 4 5 6 7 8 9 10] [-1 0 1 2 3 4 5 6 7 8]]
#+END_SRC

#+BEGIN_NOTES
Takes one step function
Runs it after each of the provided functions
#+END_NOTES

* Weighted average

#+BEGIN_SRC clojure
(defn weighted-mean [nf df]
  (let [rf (facet mean-step [nf df])]
    (completing rf (fn [x]
                     (let [[n d] (rf x)]
                       (if (zero? d) 0
                           (/ n d)))))))

(def rf
  (weighted-mean :a :b))

(transduce (map identity) rf (load-data "data.edn"))

;; => 7/6
#+END_SRC

#+BEGIN_NOTES
Using facet to calculate two means at once
#+END_NOTES

* Fuse

#+BEGIN_SRC clojure
(defn fuse [kvs]
  (let [rfns (vals kvs)
        rf   (apply juxt rfns)]
    (completing rf #(zipmap (keys kvs) (rf %)))))

(def rf
  (fuse {:one + :two conj}))

(transduce (map identity) rf (range 10))

;; => {:one 45, :two [0 1 2 3 4 5 6 7 8 9]}
#+END_SRC

#+BEGIN_NOTES
Takes heterogeneous step functions
Runs them in parallel
#+END_NOTES

* Standard deviation

#+BEGIN_SRC clojure
(defn variance
  ([] [0 0 0])
  ([[count mean sum-of-squares]]
   (/ sum-of-squares (max 1 (dec count))))
  ([[count mean sum-of-squares] x]
   (let [count' (inc count)
         mean'  (+ mean (/ (- x mean) count'))]
     [count' mean'
      (+ sum-of-squares (* (- x mean') (- x mean)))])))

(def standard-deviation
  (completing variance #(Math/sqrt (variance %))))
#+END_SRC

#+BEGIN_NOTES
- Completing added 1.7
- Adds identity completion arity
- Allows custom functions
#+END_NOTES

* Harmonise ranges

#+BEGIN_SRC clojure
(def rf
  (facet (fuse {:mean mean-step
                :sd   standard-deviation})
         [:a :b]))

(transduce (map identity) rf (load-data "data.edn"))

;; => [{:mean 70, :sd 18.257418583505537} {:mean 60, :sd 18.257418583505537}]
#+END_SRC

* Just use reduce?

#+BEGIN_SRC clojure
(def rf
  (facet (fuse {:mean mean
                :sd   standard-deviation
                :iqr  interquartile-range})
         [:a :b]))

(rf (reduce rf (rf) (load-data "data.edn")))

;; => [{:mean 70, :sd 18.257418583505537} {:mean 60, :sd 18.257418583505537}]
#+END_SRC

#+BEGIN_NOTES
No need for (map identity)

We call each of the three function arities
#+END_NOTES

* xform composition

We're used to transforming a sequence with a function.

Why not adjust a transform function with a sequence?

#+BEGIN_NOTES
- Transmap takes a transform
- a reducing function
- and a function to pass to map
#+END_NOTES

* xform composition

#+BEGIN_SRC clojure
(defn transform [xform f g xs]
  (comp xform (g (transduce xform f xs))))

(def fields [:a :b])

(def summary-stats
  (-> (fuse {:mean mean-step
             :sd   standard-deviation})
      (facet fields)))

(defn normalise [stats]
  (let [stats (zipmap fields stats)
        f (fn [x [field {:keys [mean sd]}]]
            (update-in x [field] cdf-normal :mean mean :sd sd))]
    (map #(reduce f % stats))))

(let [data (load-data "data.edn")]
  (-> (filter relevant?)
      (transform summary-stats normalise data)))
#+END_SRC

* Enter Reducers

- Prior to transducers
- Avoid intermediate collections
- Bring parallelism through Java's fork/join

#+BEGIN_NOTES
- Fork / join available in Java 7 +
- Available since 2011
#+END_NOTES

* Fork / Join

#+BEGIN_SRC clojure
solve(problem):
    if problem is small enough:
        solve problem directly (sequential algorithm)
    else:
        for part in subdivide(problem)
            fork subtask to solve part
        join all subtasks spawned in previous loop
        combine results from subtasks
#+END_SRC

#+BEGIN_NOTES
- We can already solve the subparts
- We need a way to combine their results

- Not combine like Hadoop combiner
#+END_NOTES

* Parallel reduce / combine

[[./images/reductions-tree.png]]

* ...schematically

[[./images/reduce-combine.png]]

* Mean reducers

#+BEGIN_SRC clojure
(require ['clojure.core.reducers :as r])

(defn mean-step
  ([] {:sum 0 :count 0})
  ([accum x]
   (-> (update-in accum [:count] inc)
       (update-in [:sum] + x)))
  ([{:keys [sum count]}]
   (/ sum count)))

(defn mean-combiner
  ;; Combiner is used for init value
  ([] {:sum 0 :count 0})
  ([a b]
   (merge-with + a b)))

(->> (load-data "data.edn")
     (into [] (comp xform (map :score)))
     (r/fold mean-combiner mean-step))

;; {:sum 1215.0, :count 3}
#+END_SRC

#+BEGIN_NOTES
- Fold takes the combiner and step function

- Using into Clojure's generic collection
- Again, intermediate collection before fold
- The completion function isn't called
#+END_NOTES

* Intermediate collections revisited

#+BEGIN_SRC clojure
(def scorer
  (comp xform (map :score)))

(->> (load-data "data.edn")
     (into [] scorer)
     (r/fold mean-combiner mean-step))

;; {:sum 1215.0, :count 3}

(->> (load-data "data.edn")
     (r/fold mean-combiner (scorer mean-step)))

;; {:sum 1215.0, :count 3}
#+END_SRC

#+BEGIN_NOTES
- Scorer is our transducer
- Getting a reducing function 'out of' a transducer
#+END_NOTES

* Get a reducing function back out

#+BEGIN_SRC clojure
(let [f (weighted-avg :a :b)]
 (reduce f (f) [{:a 1 :b 2} {:a 4 :b 8}]))

;; [[#object[example.core$wrapping$fn__80296 0x3f478522 "example.core$wrapping$fn__80296@3f478522"] #object[clojure.lang.Volatile 0x573499fb {:status :ready, :val {:sum 5, :count 2}}]] [#object[example.core$wrapping$fn__80296 0x414f525c "example.core$wrapping$fn__80296@414f525c"] #object[clojure.lang.Volatile 0x179ba0e5 {:status :ready, :val {:sum 10, :count 2}}]]]
#+END_SRC

* 
:PROPERTIES:
:reveal_background: ./images/synth/SynthMIT-M-1.jpg
:CUSTOM_ID: paradiso
:END:

* Anatomy of a transducer

#+BEGIN_SRC clojure
(defn filter' [pred]
  (fn [rf]
    (fn
      ([] (rf))
      ([result] (rf result))
      ([result input]
       (if (pred input)
         (rf result input)
         result)))))

(transduce (filter' even?) conj [1 2 3 4 5 6])

;; [2 4 6]
#+END_SRC

#+BEGIN_NOTES
- transducers are just functions of 3 arities
- arity zero is init
- arity one is completion
- arity two is the reducing function
- all just function composition
- these ideas are general
#+END_NOTES

* Enter core.async

Core async has a reduce, but no combine.

Combine is just another reduce over the intermediate steps.

#+BEGIN_SRC clojure
(defn pipeline-r [n f g xs]
  (let [in (async/chan n)]
    (async/onto-chan in xs)
    (->> (for [_ (range n)]
           (async/reduce f (f) in))
         (async/merge)
         (async/reduce g (g))
         (async/< !!)
         (f))))
#+END_SRC

* Simple Regression

#+BEGIN_SRC clojure
(defn calculate-coefficients [{:keys [covariance variance-x
                                      mean-x mean-y]}]
  (let [slope (/ covariance variance-x)]
    {:intercept (- mean-y (* mean-x slope))
     :slope     slope}))

(defn linear-regression [fx fy fold]
  (->> fold
       (t/fuse {:covariance (m/covariance fx fy)
                :variance-x (m/variance (t/map fx))
                :mean-x (m/mean (t/map fx))
                :mean-y (m/mean (t/map fx))})
       (t/post-combine calculate-coefficients)))

(def linear-regression-fold
  (->> (t/filter relevant?)
       (t/map convert-currency)
       (linear-regression :a :b)))

(-> (t/chunk 1024 (load-data "data.edn"))
    (t/tesser linear-regression-fold))

;; {:intercept 68.05555555555557, :slope 0.6666666666666666}
#+END_SRC

#+BEGIN_NOTES
- Having calculated many statistics
- Want to perform some post-processing on the results
- Keep it within the fold

- Where's my cake?
#+END_NOTES

* Reducing function Rules
- Always call completion
- Respect reduced
* Summary

- Separate process from substrate
- Transducers, step functions and transducible processes
- Reducing and combining functions
- Create composable, extensible units of computation
- Defer decisions about context
- Benefit

* Thanks!

https://github.com/henrygarner/data-science-london-oct-2015

[[./images/henrygarner.jpeg]]

Henry Garner

@henrygarner

* If you liked this...

http://cljds.com/cljds-book | 
http://cljds.com/cljds-amzn

[[./images/clojure-data-science.png]]

#+BEGIN_NOTES
- This is new material
- Cover Clojure applied to statistical analysis
- Ideally you know a little Clojure already
- Learn statistics and machine learning with Clojure
#+END_NOTES

* References

https://github.com/cgrand/xforms
https://github.com/aphyr/tesser
